<html>
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script
      id="MathJax-script"
      async
      src="https://polyfill.io/v3/|latest?features=es6"
    ></script>
    <title>Homework 3 Report</title>
    <script
      type="text/javascript"
      async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"
    ></script>
    <style>
      body {
        font-family: "Trebuchet MS", "Lucida Sans Unicode", "Lucida Grande",
          "Lucida Sans";
        line-height: 1.6;
        margin-top: 5%;
        margin-left: 15%;
        margin-right: 15%;
        margin-bottom: 10%;
      }

      h1,
      h2,
      h3,
      h4,
      h5,
      h6 {
        color: #333;
      }

      section {
        margin-bottom: 20px;
      }

      h2 {
        border-bottom: 2px solid #333;
        padding-bottom: 5px;
      }

      h3 {
        margin-bottom: 2px;
      }
      ul {
        list-style-type: none;
        padding: 0;
      }

      li {
        margin-bottom: 10px;
      }
      a:link {
        color: purple;
        background-color: transparent;
        text-decoration: none;
      }

      a:visited {
        color: purple;
        background-color: transparent;
        text-decoration: none;
      }

      a:hover {
        color: #0abab5;
        background-color: transparent;
        text-decoration: underline;
      }

      a:active {
        color: #10098f;
        background-color: transparent;
        text-decoration: underline;
      }
      *::first-letter {
        text-transform: uppercase;
      }
      ul {
        list-style-type: disc; /* Default is disc */
      }
      table {
        font-family: "Trebuchet MS", "Lucida Sans Unicode", "Lucida Grande",
          "Lucida Sans";
        border-collapse: collapse;
        width: 100%;
        margin-top: 15px;
      }

      th,
      td {
        border: 1px solid #dddddd;
        text-align: left;
        padding: 8px;
      }

      th {
        background-color: #f2f2f2;
      }

      tr td:nth-child(1) {
        background-color: #f2f2f2;
        font-weight: bold;
      }
    </style>
  </head>

  <body>
    <header>
      <h1>Report for Homework 3: Pathtracer</h1>
      <p>Date: Mar 4, 2024</p>
      <p>
        Group Member:
        <a href="https://github.com/whydarren-6uom">Darren Wang</a>,
        <a href="https://github.com/Sunnyweather1314">Jiayi Xu</a>
      </p>
    </header>

    <section id="overview">
      <h2>Homework Description</h2>
      <p>
        In this assignment, you will explore topics on geometric modeling
        covered in lecture. You will build Bezier curves and surfaces using de
        Casteljau algorithm, manipulate triangle meshes represented by half-edge
        data structure, and implement loop subdivision.
      </p>
    </section>

    <section id="Part1">
      <h2>Part 1: Ray Generation and Scene Intersection</h2>
      <h3>Generating Rays and Primitive Intersection</h3>
      <p>
        We determine the original point's position and project it onto the
        screen. To find
        <span style="background-color: rgb(220, 220, 217)">new_x</span> and
        <span style="background-color: rgb(220, 220, 217)">new_y</span>, we
        center the original rectangle screen defined by (0, 0) and (1, 1) at (0,
        0), resulting in (x - 0.5, y - 0.5). The relative positions of
        <span style="background-color: rgb(220, 220, 217)">x</span> and
        <span style="background-color: rgb(220, 220, 217)">y</span> in the
        original screen remain the same as
        <span style="background-color: rgb(220, 220, 217)">new_x</span> and
        <span style="background-color: rgb(220, 220, 217)">new_y</span>. This
        leads to the equations:
        <br />
        \[\frac{(x - 0.5)}{1} = \frac{\text{new_x}}{(2 \cdot
        \tan(\text{radians(hFov) * .5}))}\] \[\frac{(y - 0.5)}{1} =
        \frac{\text{new_y}}{(2 \cdot \tan(\text{radians(vFov) * .5}))}\]
        <br />
        We obtain
        <span style="background-color: rgb(220, 220, 217)"
          >Vector3D ray_vector = Vector3D(new_x, new_y, -1.0)</span
        >. After obtaining the position of the projected point, we calculate the
        direction vector of
        <span style="background-color: rgb(220, 220, 217)">result_ray</span>
        using matrix multiplication
        <span style="background-color: rgb(220, 220, 217)"
          >c2w * ray_vector</span
        >. Finally, we set the visible boundary for this ray between nClip and
        fClip, which we will update later.
      </p>
      <h3>Process walkthrough</h3>
      <p>
        Ray generation begins with casting rays from the virtual camera into the
        scene. Each ray is defined by its origin (the camera's position) and a
        direction (pointing through a pixel on the camera plane). These rays
        traverse the scene, interacting with objects along their directions. The
        primitive intersection stage involves determining if a ray intersects
        with any geometric primitives(sphere, triangle, etc.) in the scene. This
        process employs the function
        <span style="background-color: rgb(220, 220, 217)"
          >Triangle::intersect</span
        >
        or
        <span style="background-color: rgb(220, 220, 217)"
          >Sphere::intersect</span
        >. When an intersection is detected, information about the point of
        intersection, such as its position, surface properties, and material
        characteristics, will be upadted in the struct
        <span style="background-color: rgb(220, 220, 217)"
          >Intersection* isect</span
        >.
      </p>

      <h3>triangle intersection algorithm</h3>
      <p>
        We used the Moller Trumbore Algorithm that we have discussed in lecture.
        After following the steps and get the vector containing [t, alpha,
        beta], we first see if t is between
        <span style="background-color: rgb(220, 220, 217)">r.min_t</span> and
        <span style="background-color: rgb(220, 220, 217)">r.max_t</span> and if
        alpha and beta are within [0, 1]. If any of the condition fails, the
        intersection is not suppose to happen and we return false. If both
        conditions are met, we update the intersection information to
        <span style="background-color: rgb(220, 220, 217)"
          >Intersection* isect</span
        >, including the filed t, primitive, bsdf and n(calculated by doing
        barycentric interpolation with the current three norms and the alpha,
        beta, gamma values that we calculated above.) We also updated ray.max_t
        to t.
      </p>
      <h3>Screenshots</h3>

      <div style="display: flex; justify-content: center; align-items: center">
        <div
          style="
            display: flex;
            justify-content: center;
            align-items: center;
            flex-direction: column;
          "
        >
          <img src="task1_bunny.png" style="width: 100%" />
          <img src="task1_banana.png" style="width: 100%" />
          <img src="task1_CBspheres.png" style="width: 100%" />
        </div>
      </div>
    </section>

    <section id="Part2">
      <h2>Part 2: Bounding Volume Hierarchy</h2>
      <h3>BVH construction algorithm</h3>
      <p>Following are our steps for constructing BVH</p>
      <ul>
        <li>
          <b>Compute the Bounding Box (bbox)</b>: We start by computing the
          bounding box that encloses all the primitives between
          <span style="background-color: rgb(220, 220, 217)">start</span> and
          <span style="background-color: rgb(220, 220, 217)">end</span>. The
          bounding box is computed by iteratively expanding it to include the
          bounding boxes of individual primitives using function
          <span style="background-color: rgb(220, 220, 217)">bbox.expand</span>.
        </li>
        <li>
          <b>Choose Splitting Axis</b>: We then choose the splitting axis based
          on the maximum extent of the bounding box. The axis is selected to be
          the one along which the bounding box has the maximum size. This
          heuristic helps achieve a more balanced partitioning.
        </li>
        <li>
          <b>Check Leaf Node Condition</b>: If the number of primitives in the
          current range is less than or equal to
          <span style="background-color: rgb(220, 220, 217)">max_leaf_size</span
          >, the current node becomes a leaf node. We just create a leaf node
          and set its start and end field with the input
          <span style="background-color: rgb(220, 220, 217)">start</span> and
          <span style="background-color: rgb(220, 220, 217)">end</span>.
        </li>
        <li>
          <b>Partition Primitives</b>: If the number of primitives exceeds
          <span style="background-color: rgb(220, 220, 217)">max_leaf_size</span
          >, we partition the primitives along the chosen axis. We used the
          function
          <span style="background-color: rgb(220, 220, 217)">nth_element</span>
          to partially sort the primitives based on their centroids along the
          selected axis. This effectively places the median primitive at the
          position that separates the primitives into two groups.
        </li>
        <li>
          <b>Construction</b>: Then, we recursively constructs the left and
          right child nodes of the current node, each covering a subset of the
          primitives. The left child covers the range [start, start + size/2),
          and the right child covers the range [start + size/2, end]. Finally,
          we return the current node.
        </li>
      </ul>
      <h3>screenshots of large images with normal shading</h3>
      <div style="display: flex; justify-content: center; margin-top: 15px">
        <div style="flex-direction: column">
          <img src="task2_beast.png" style="width: 100%" />
          <img src="task2_peter.png" style="width: 100%" />

          <img src="task2_cow.png" style="width: 100%" />
          <img src="task2_CBlucy.png" style="width: 100%" />
        </div>
      </div>
      <h3>Render Time Comparison Analysis</h3>
      <p>
        Before implementing BVH acceleration, the rendering time for cow was
        close to a minute. After implementing BVH, the rendering time for cow is
        around 1 second. And all the other large .dae files(the ones above) all
        takes at most 2 seconds to complete. The speed-up is much faster, we
        think this is because once a ray does not intersect with a node's bbox,
        we do not test for intersection between the ray and the primitives
        contained by the node, which saves us a lot of computation.
      </p>
    </section>

    <section id="Part3">
      <h2>Part 3: Direct Illumination</h2>
      <h3>
        Walkthough for
        <span style="background-color: rgb(220, 220, 217)"
          >Vector3D PathTracer::estimate_direct_lighting_hemisphere</span
        >
      </h3>
      <ul>
        <li>
          <b>Sampling Loop for Direct Lighting</b>: We start a num_samples times
          loop to sample the hemisphere around the hit point, considering the
          lights in the scene.
        </li>
        <li>
          <b>Sample Light</b>: Within the loop, we get the sampled light by
          calling
          <span style="background-color: rgb(220, 220, 217)"
            >isect.bsdf->sample_f</span
          >. This function returns the sampled reflected direction wj and the
          corresponding probability density function (pdf). Then, we multiply
          the direction vector by
          <span style="background-color: rgb(220, 220, 217)">o2w</span> to get
          the transformed vector and normalize it. Then, we construct the
          sampleray using hit_p as origin and the normalized vector as direction
          with its min_t set to EPS_F and max_t set to INF_D.
        </li>
        <li>
          <b>Check for Intersection</b>: If sampleray intersects with the scene,
          we calculate the contribution for L_out by this sampleray using the
          function
          <span style="background-color: rgb(220, 220, 217)"
            >lightIsect.bsdf->get_emission() * f * abs_cos_theta(wj) / pdf</span
          >
          and add it to L_out.
        </li>
        <li>
          <b>Normalizing Output</b>: Finally, we return the light estimator
          equals to L_out / num_samples.
        </li>
      </ul>

      <h3>
        Walkthough for
        <span style="background-color: rgb(220, 220, 217)"
          >Vector3D PathTracer::estimate_direct_lighting_importance</span
        >
      </h3>
      <ul>
        <li>
          <b>Sampling Loop for Direct Lighting</b>: We start a num_samples times
          loop to sample the hemisphere around the hit point, considering the
          lights in the scene.
        </li>
        <li>
          <b>Sample Light</b>: Within the loop, we get the sampled light by
          calling
          <span style="background-color: rgb(220, 220, 217)"
            >isect.bsdf->sample_f</span
          >. This function returns the sampled reflected direction wj and the
          corresponding probability density function (pdf). Then, we multiply
          the direction vector by
          <span style="background-color: rgb(220, 220, 217)">o2w</span> to get
          the transformed vector and normalize it. Then, we construct the
          sampleray using hit_p as origin and the normalized vector as direction
          with its min_t set to EPS_F and max_t set to INF_D.
        </li>
        <li>
          <b>Check for Intersection</b>: If sampleray intersects with the scene,
          we calculate the contribution for L_out by this sampleray using the
          function
          <span style="background-color: rgb(220, 220, 217)"
            >lightIsect.bsdf->get_emission() * f * abs_cos_theta(wj) / pdf</span
          >
          and add it to L_out.
        </li>
        <li>
          <b>Normalizing Output</b>: Finally, we return the light estimator
          equals to L_out / num_samples.
        </li>
      </ul>

      <h3>
        Comparison and Analysis of uniform hemisphere sampling and lighting
        sampling
      </h3>
      <div style="display: flex; justify-content: center; margin-top: 15px">
        <div style="flex-direction: column">
          <figure>
            <img src="task3_spheres_H.png" style="width: 100%" />
            <figcaption>
              CBspheres_lambertian.dae using estimate_direct_lighting_hemisphere
            </figcaption>
          </figure>
          <figure>
            <img src="task3_spheres_I.png" style="width: 100%" />
            <figcaption>
              CBspheres_lambertian.dae using estimate_direct_lighting_importance
            </figcaption>
          </figure>
        </div>
        <div style="flex-direction: column">
          <figure>
            <img src="task3_bunny_H.png" style="width: 100%" />
            <figcaption>
              CBbunny.dae using estimate_direct_lighting_hemisphere
            </figcaption>
          </figure>
          <figure>
            <img src="task3_bunny_I.png" style="width: 100%" />
            <figcaption>
              CBbunny.dae using estimate_direct_lighting_importance
            </figcaption>
          </figure>
        </div>
      </div>
      <div style="display: flex; justify-content: center; margin-top: 15px">
        <div style="flex-direction: column">
          <figure>
            <img src="task3_coil_H.png" style="width: 100%" />
            <figcaption>
              CBcoil.dae using estimate_direct_lighting_hemisphere
            </figcaption>
          </figure>
          <figure>
            <img src="task3_coil_I.png" style="width: 100%" />
            <figcaption>
              CBcoil.dae using estimate_direct_lighting_importance
            </figcaption>
          </figure>
        </div>
        <div style="flex-direction: column">
          <figure>
            <img src="task3_CBgems_H.png" style="width: 100%" />
            <figcaption>
              CBgems.dae using estimate_direct_lighting_hemisphere
            </figcaption>
          </figure>
          <figure>
            <img src="task3_CBgems_I.png" style="width: 100%" />
            <figcaption>
              CBgems.dae using estimate_direct_lighting_importance
            </figcaption>
          </figure>
        </div>
      </div>
      <p>
        Uniform hemisphere sampling provides an unbiased, yet more visually
        noisy representation, especially in regions where there are intricate
        interactions between light and surfaces. In contrast, light sampling, by
        strategically sampling directions based on the light source, tends to
        produce smoother results with reduced noise levels in areas affected by
        soft shadows.
      </p>

      <h3>
        Comparison Between Noise Levels in Soft Shadows Using Lighting Sampling
      </h3>
      <div style="display: flex; justify-content: center; margin-top: 15px">
        <div style="flex-direction: column">
          <figure>
            <img src="task3_ bunny_1_1.png" style="width: 100%" />
            <figcaption>CBbunny.dae l = 1, s = 1</figcaption>
          </figure>
          <figure>
            <img src="task3_ bunny_1_4.png" style="width: 100%" />
            <figcaption>CBbunny.dae l = 4, s = 1</figcaption>
          </figure>
        </div>
        <div style="flex-direction: column">
          <figure>
            <img src="task3_ bunny_1_16.png" style="width: 100%" />
            <figcaption>CBbunny.dae l = 16, s = 1</figcaption>
          </figure>
          <figure>
            <img src="task3_ bunny_1_64.png" style="width: 100%" />
            <figcaption>CBbunny.dae l = 64, s = 1</figcaption>
          </figure>
        </div>
      </div>
      <p>
        As the number of light rays (l) increases in the rendering process with
        light sampling, the transitions of shadows become smoother and the
        presence of noisy pixels diminishes. This improvement is attributed to
        the increased number of samples per pixel, leading to more accurate and
        refined estimations of soft shadows, resulting in a visually smoother
        and less noisy appearance in the illuminated regions of the scene.
      </p>
    </section>

    <section id="Part4">
      <h2>Part 4: Global Illumination</h2>
      <h3>Implementation</h3>
      <p>
        The function takes an iterator pointing to a halfedge as input. This
        halfedge represents the edge that will be flipped.
      </p>
      <h3>Steps</h3>
      <ol>
        <li>
          Check for Boundary Edge: first checks if the input edge is a boundary
          edge. If it is, flipping is not possible, so the function simply
          returns the original edge iterator.
        </li>
        <li>
          Get Halfedge: obtains iterators for several halfedges surrounding the
          edge to be flipped, namely 3 halfedges for Left and 3 halfedges for
          Right. These iterators are used to update connections between
          halfedges after the flip.
        </li>
        <li>
          Get Vertex: obtains iterators for the four vertices in the diagram
          connected to the halfedges. These iterators are used to update the
          vertices' halfedge pointers after the flip.
        </li>
        <li>
          Get Face: obtains iterators for the two faces, namely Left and Right,
          that the two halfedges being flipped belong to. These iterators are
          used to update the faces' halfedge pointers after the flip.
        </li>
        <li>
          Update Halfedge Neighbors (via
          <span style="background-color: rgb(220, 220, 217)"
            >setNeighbors()</span
          >): updates the neighbor pointers of the four halfedges involved in
          the flip. This step reconfigures the connections between halfedges to
          reflect the flipped edge.
        </li>
        <li>
          Update Halfedge Next Pointers: updates the "next" pointers of two
          halfedges to reverse their order in the counter-clockwise direction
          around their respective faces.
        </li>
        <li>
          Update Vertex Halfedge Pointers: updates the "halfedge" pointers of
          the four vertices involved in the flip to point to their new
          corresponding halfedges after the flip.
        </li>
        <li>
          Update Face Halfedge Pointers: updates the "halfedge" pointers of the
          two faces involved in the flip to point to their new starting
          halfedges after the flip.
        </li>
        <li>
          Return Flipped Edge: The function returns the iterator pointing to the
          original edge, which now represents the flipped edge.
        </li>
      </ol>
      <h3>Debugging</h3>
      <p>
        We used the diagram to help us understand the connections between the 4
        halfedges and 4 vertices involved in the flip. We also used the diagram
        to help us understand the connections between the 2 faces involved in
        the flip.
      </p>
      <div style="display: flex; justify-content: center; margin-top: 15px">
        <img src="S2P4-Diagram.jpg" style="width: 100%" />
      </div>
      <h3>Result</h3>
      <div style="display: flex; justify-content: center; margin-top: 15px">
        <div style="flex-direction: column">
          <figure>
            <img src="task3_spheres_H.png" style="width: 100%" />
            <figcaption>
              CBspheres_lambertian.dae using estimate_direct_lighting_hemisphere
            </figcaption>
          </figure>
          <figure>
            <img src="task3_spheres_I.png" style="width: 100%" />
            <figcaption>
              CBspheres_lambertian.dae using estimate_direct_lighting_importance
            </figcaption>
          </figure>
        </div>
        <div style="flex-direction: column">
          <figure>
            <img src="task3_dragon_H.png" style="width: 100%" />
            <figcaption>
              dragon.dae using estimate_direct_lighting_hemisphere
            </figcaption>
          </figure>
          <figure>
            <img src="task3_dragon_I.png" style="width: 100%" />
            <figcaption>
              dragon.dae using estimate_direct_lighting_importance
            </figcaption>
          </figure>
        </div>
      </div>

      <h3>
        Comparison between uniform hemisphere sampling and lighting sampling
      </h3>
      <p></p>
      noise levels in soft shadows
      <h3>
        Comparison between uniform hemisphere sampling and lighting sampling
      </h3>
      <p></p>
    </section>

    <section id="Part4">
      <h2>Task 5: Edge Split (15 pts)</h2>
      <h2>Steps</h2>
      <p>
        Please refer to the diagram below for the notations of the vertices,
        halfedges and faces as we have created new ones.
      </p>
      <p>
        For your reference, vertices starting with "M" means "from the
        Midpoint", "U" means "from the Upper face", "D" means "from the Down
        face", "L" means "from the Left face", "R" means "from the Right face".
      </p>
      <div style="display: flex; justify-content: center; margin-top: 15px">
        <img src="S2P5-Diagram.jpg" style="width: 100%" />
      </div>
      <ol>
        <li>
          Create New Mesh Elements: The function first creates several new
          elements to be inserted into the mesh during the split:
          <ul>
            <li>
              A new vertex ("MID") to represent the midpoint of the split edge.
            </li>
            <li>
              Three new edges ("MD", "MB", "MA") to form the new edges after the
              split.
            </li>
            <li>
              Six new halfedges ("UR3", "DR3", "DR0", "DL0", "DL3", "UL3") to
              connect the new vertex and edges.
            </li>
            <li>
              Two new faces ("UP", "DOWN") to fill the gaps created by the
              split.
            </li>
          </ul>
        </li>
        <li>
          Get Iterators for Existing Elements: The function obtains iterators
          for existing halfedges, faces, and vertices surrounding the edge to be
          split. These iterators are used to update connections after the split.
        </li>
        <li>
          Position the New Vertex The position of the new vertex ("MID") is set
          to the average of the positions of the two original vertices connected
          by the edge.
        </li>
        <li>
          Set Initial Halfedge Pointers: The "halfedge" pointer of the new
          vertex ("MID") is set to point to one of the original halfedges
          ("L0_OLD"). The "halfedge" pointer of the original vertex's vertex is
          updated to point to a new halfedge on the opposite face ("R1_OLD").
        </li>
        <li>
          Set Face Halfedge Pointers: The "halfedge" pointers of the new and
          existing faces are updated to point to appropriate halfedges, ensuring
          correct face-vertex relationships.
        </li>
        <li>
          Set Edge Halfedge Pointers: The "halfedge" pointers of the new edges
          are set to point to their corresponding halfedges.
        </li>
        <li>
          Update Existing Halfedge Neighbors: The neighbor pointers of the
          existing halfedges are modified to accommodate the new vertex and
          edges, maintaining mesh connectivity.
        </li>
        <li>
          Set New Halfedge Neighbors: The neighbor pointers of the new halfedges
          are set to correctly connect them to the existing mesh elements,
          forming the new edges and faces.
        </li>
        <li>
          Return the New Vertex: The function returns an iterator pointing to
          the newly inserted vertex ("MID").
        </li>
      </ol>
      <h3>Result</h3>
      <div style="display: flex; justify-content: center; margin-top: 15px">
        <div style="flex-direction: column">
          <img src="S2P5-0.png" style="width: 100%" />
          <img src="S2P5-1.png" style="width: 100%" />
        </div>
        <div style="flex-direction: column">
          <img src="S2P5-2.png" style="width: 100%" />
          <img src="S2P5-3.png" style="width: 100%" />
        </div>
      </div>
    </section>
  </body>
</html>
